{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTM & TF-IDF OF 1880s FICTION\n",
    "\n",
    "- Let's take up Ramsay's project. We'll use some Python packages to analyze 1880s British fiction. We'll explore the data, make a document term matrix. We'll then use the DTM and a word weighting technique called TF-IDF (term frequency inverse document frequency) to identify important and discerning words within this dataset with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We start by importing the modules and packages we need, and we define the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('seaborn-poster')\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "DATA_DIR = 'data/test' # Locate the directory for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing text files ##\n",
    "Define a function `list_textfiles`, taking a parameter `directory`, that: \n",
    "   - lists all the text files in `directory`\n",
    "   - adds that text file to a new list, written as \"folder/file\"\n",
    "   - returns the new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt' in DIRECTORY. Remove files that are (almost) empty.\"\n",
    "    textFiles = []\n",
    "    # We are sorting because different operating systems may list files in different orders\n",
    "    for fileName in sorted(os.listdir(directory)):\n",
    "        if fileName.endswith(\".txt\"):\n",
    "            textFiles.append(directory + \"/\" + fileName)\n",
    "    return textFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing ##\n",
    "\n",
    "Define a function `tokenizer`, taking a parameter `filename`, that:\n",
    "   - opens `filename`\n",
    "   - reads its contents\n",
    "   - turns all characters into lower case\n",
    "   - removes punctuation\n",
    "   - tokenizes the words (use whatever tokenizer you like)\n",
    "   - removes stopwords (hint: look at the stopwords module we installed)\n",
    "   - returns a list containing the cleaned up words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        start = timer()\n",
    "        text = f.read()\n",
    "        lower = text.lower()\n",
    "        no_punctuation = ''.join(ch for ch in lower if unicodedata.category(ch)[0] != 'P')\n",
    "        words = word_tokenize(no_punctuation)\n",
    "        stop_words = stopwords.words('english') \n",
    "        end = timer()\n",
    "        print(\"function took \" + str(end - start) + \" ms\")\n",
    "        return [w for w in words if w not in stop_words and not w.isdigit() and len(w)>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing text files ##\n",
    "\n",
    "We'll run the functions we've just created:\n",
    "   - Create a new list, `total`\n",
    "   - Call list_textfiles with argument DATA_DIR and store its returned contents in a new variable `file_list`\n",
    "   - Add a for-loop iterating over `file_list` that:\n",
    "       - runs the `tokenizer` function with each file from `file_list` as argument\n",
    "       - turns the tokens back into strings using the `' '.join()` function, saving this in variable `strings`\n",
    "       - runs an `*if*` statement that checks if the file name ends with `\"_female.txt\"` (hint: look up the `os.path.basename` function), and if so, appends the letter \"F\" and the `strings` variable to a new list *inside* the `total` list.\n",
    "       - runs an `*else*` statement that appends the letter \"M\" and the `strings` variable to a new list *inside* the `total` list.\n",
    "    - Create a numpy array from the `total` list, called `total_array`\n",
    "    - Print `total_array` to see if it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function took 0.0005254239949863404 ms\n",
      "function took 0.000804812996648252 ms\n",
      "function took 0.0012806779996026307 ms\n",
      "[['F' 'selecting useful dress materials manufactured messrs']\n",
      " ['M'\n",
      "  'village nearest market altringham two miles away nearest church bowdon like distance road came direct village baguley moor crossed fairy well brook reached oaklandss timperley hall timperley brook ere branched right left acute angle altringham bowdon']\n",
      " ['M'\n",
      "  'sooner taken pen hand intention writing intimate friend toady ascham make inquiries concerning schools general sound pattering feet corridor followed many thumps door attended shouts mammy mammy feet moment opened door soon hugging riotous screaming boy whip hand child master bruce answered pathetic inquiries matter sobbing repetitions word janet janet janet darling asked mother soothingly nothing maam replied respectablelooking middleaged woman followed master bruce kept whipping teasing miss janet pushed away tumbled would smudge drawing maam']]\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "file_list = list_textfiles(DATA_DIR)\n",
    "for filepath in file_list:\n",
    "    tokens = tokenizer(filepath)\n",
    "    strings = ' '.join(tokens)\n",
    "    if os.path.basename(filepath).endswith(\"_female.txt\"):\n",
    "        total.append([\"F\", strings])    \n",
    "    else:\n",
    "        total.append([\"M\", strings])\n",
    "total_array = np.asarray(total)\n",
    "print(total_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "janet           4\n",
       "bowdon          2\n",
       "followed        2\n",
       "door            2\n",
       "hand            2\n",
       "inquiries       2\n",
       "nearest         2\n",
       "bruce           2\n",
       "brook           2\n",
       "timperley       2\n",
       "master          2\n",
       "feet            2\n",
       "mammy           2\n",
       "altringham      2\n",
       "village         2\n",
       "maam            2\n",
       "away            2\n",
       "manufactured    1\n",
       "friend          1\n",
       "general         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer()\n",
    "sparse_dtm = countvec.fit_transform(total_array[:, 1])\n",
    "dtm = pd.DataFrame(sparse_dtm.toarray(), columns=countvec.get_feature_names())\n",
    "# Quickly identify the most frequent words:\n",
    "dtm.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "janet        1.333333\n",
       "bowdon       0.666667\n",
       "followed     0.666667\n",
       "door         0.666667\n",
       "hand         0.666667\n",
       "inquiries    0.666667\n",
       "nearest      0.666667\n",
       "bruce        0.666667\n",
       "brook        0.666667\n",
       "timperley    0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the average number of times each word is used in a book:\n",
    "dtm.mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We turn the text into a document term matrix using the scikit-learn function called `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "materials       0.408248\n",
       "useful          0.408248\n",
       "selecting       0.408248\n",
       "dress           0.408248\n",
       "manufactured    0.408248\n",
       "messrs          0.408248\n",
       "janet           0.389289\n",
       "bowdon          0.289951\n",
       "village         0.289951\n",
       "brook           0.289951\n",
       "altringham      0.289951\n",
       "timperley       0.289951\n",
       "nearest         0.289951\n",
       "door            0.194645\n",
       "followed        0.194645\n",
       "feet            0.194645\n",
       "maam            0.194645\n",
       "master          0.194645\n",
       "mammy           0.194645\n",
       "inquiries       0.194645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "sparse_tfidf = vectorizer.fit_transform(total_array[:, 1])\n",
    "tfidf = pd.DataFrame(sparse_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "tfidf.max().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf['gender_'] = total_array[:, 0]\n",
    "male = tfidf[tfidf['gender_']=='M']\n",
    "female = tfidf[tfidf['gender_']=='F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "materials       0.408248\n",
       "messrs          0.408248\n",
       "selecting       0.408248\n",
       "useful          0.408248\n",
       "dress           0.408248\n",
       "manufactured    0.408248\n",
       "make            0.000000\n",
       "hand            0.000000\n",
       "ere             0.000000\n",
       "fairy           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.max(numeric_only=True).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "janet         0.389289\n",
       "nearest       0.289951\n",
       "altringham    0.289951\n",
       "village       0.289951\n",
       "timperley     0.289951\n",
       "bowdon        0.289951\n",
       "brook         0.289951\n",
       "feet          0.194645\n",
       "mammy         0.194645\n",
       "door          0.194645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male.max(numeric_only=True).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
